Topic: A Survey of Spiking Neural Networks and Their Applications

Bibliography of Literature Found: (As of March 16, 2025 – To be updated as literature search continues)

🔵	Ghosh-Dastidar, S., & Adeli, H. (2009). Spiking neural networks. International journal of neural systems, 19(04), 295-308. https://doi.org/10.1142/S0129065709002002

🔵	Tavanaei, A., Ghodrati, M., Kheradpisheh, S. R., Masquelier, T., & Maida, A. (2019). Deep learning in spiking neural networks. Neural networks, 111, 47-63. https://doi.org/10.1016/j.neunet.2018.12.002

🔵	Bouvier, M., Valentian, A., Mesquida, T., Rummens, F., Reyboz, M., Vianello, E., & Beigne, E. (2019). Spiking neural networks hardware implementations and challenges: A survey. ACM Journal on Emerging Technologies in Computing Systems (JETC), 15(2), 1-35. https://doi.org/10.1145/3304103

🔵	Kudithipudi, D., Schuman, C., Vineyard, C. M., Pandit, T., Merkel, C., Kubendran, R., ... & Furber, S. (2025). Neuromorphic computing at scale. Nature, 637(8047), 801-812. https://doi.org/10.1038/s41586-024-08253-8

🔵	Yamazaki, K., Vo-Ho, V.-K., Bulsara, D., & Le, N. (2022). Spiking Neural Networks and Their Applications: A Review. Brain Sciences, 12(7), 863. https://doi.org/10.3390/brainsci12070863

🔵	Sanaullah, Koravuna, S., Rückert, U., & Jungeblut, T. (2023). Exploring spiking neural networks: A comprehensive analysis of mathematical models and applications. Frontiers in Computational Neuroscience, 17. https://doi.org/10.3389/fncom.2023.1215824

🔵	Pietrzak, P., Szczęsny, S., Huderek, D., & Przyborowski, Ł. (2023). Overview of Spiking Neural Network Learning Approaches and Their Computational Complexities. Sensors, 23(6), 3037. https://doi.org/10.3390/s23063037

🔵	Maass, W. (1997). Networks of spiking neurons: the third generation of neural network models. Neural networks, 10(9), 1659-1671. https://doi.org/10.1016/S0893-6080(97)00011-7

🔵	Benjamin, B. V., Gao, P., McQuinn, E., Choudhary, S., Chandrasekaran, A. R., Bussat, J. M., ... & Boahen, K. (2014). Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations. Proceedings of the IEEE, 102(5), 699-716. https://doi.org/10.1109/JPROC.2014.2313565

🔵	Davies, M., Srinivasa, N., Lin, T. H., Chinya, G., Cao, Y., Choday, S. H., ... & Wang, H. (2018). Loihi: A neuromorphic manycore processor with on-chip learning. IEEE Micro, 38(1), 82-99. https://doi.org/10.1109/MM.2018.112130359

🔵	Furber, S. B., Galluppi, F., Temple, S., & Plana, L. A. (2014). The spinnaker project. Proceedings of the IEEE, 102(5), 652-665. https://doi.org/10.1109/JPROC.2014.2304638

🔵	Merolla, P. A., Arthur, J. V., Alvarez-Icaza, R., Cassidy, A. S., Sawada, J., Akopyan, F., ... & Modha, D. S. (2014). A million spiking-neuron integrated circuit with a scalable communication network and interface. Science, 345(6197), 668-673. https://doi.org/10.1126/science.1254642

🔵	Schemmel, J., Brüderle, D., Grübl, A., Hock, M., Meier, K., & Millner, S. (2010, May). A wafer-scale neuromorphic hardware system for large-scale neural modeling. In 2010 IEEE international symposium on circuits and systems (iscas) (pp. 1947-1950). IEEE. https://doi.org/10.1109/ISCAS.2010.5536970

🔵	Diehl, P. U., & Cook, M. (2015). Unsupervised learning of digit recognition using spike-timing-dependent plasticity. Frontiers in computational neuroscience, 9, 99. https://doi.org/10.3389/fncom.2015.00099

🔵	Mostafa, H., Pedroni, B. U., Sheik, S., & Cauwenberghs, G. (2017, May). Fast classification using sparsely active spiking networks. In 2017 IEEE International Symposium on Circuits and Systems (ISCAS) (pp. 1-4). IEEE. https://doi.org/10.1109/ISCAS.2017.8050527

🔵	Srinivasan, G., & Roy, K. (2019). Restocnet: Residual stochastic binary convolutional spiking neural network for memory-efficient neuromorphic computing. Frontiers in neuroscience, 13, 189. https://doi.org/10.3389/fnins.2019.00189

🔵	Zhang, M., Gu, Z., Zheng, N., Ma, D., & Pan, G. (2020). Efficient spiking neural networks with logarithmic temporal coding. IEEE access, 8, 98156-98167. https://doi.org/10.1109/ACCESS.2020.2994360

🔵	Zhang, W., & Li, P. (2020). Temporal spike sequence learning via backpropagation for deep spiking neural networks. Advances in neural information processing systems, 33, 12022-12033. https://doi.org/10.48550/arXiv.2002.10085

🔵	Rueckauer, B., & Liu, S. C. (2018, May). Conversion of analog to spiking neural networks using sparse temporal coding. In 2018 IEEE international symposium on circuits and systems (ISCAS) (pp. 1-5). IEEE. https://doi.org/10.1109/ISCAS.2018.8351295

🔵	Han, B., & Roy, K. (2020, August). Deep spiking neural network: Energy efficiency through time based coding. In European conference on computer vision (pp. 388-404). Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-58607-2_23

🔵	Sengupta, A., Ye, Y., Wang, R., Liu, C., & Roy, K. (2019). Going deeper in spiking neural networks: VGG and residual architectures. Frontiers in neuroscience, 13, 95. https://doi.org/10.3389/fnins.2019.00095

🔵	Rathi, N., Srinivasan, G., Panda, P., & Roy, K. (2020). Enabling deep spiking neural networks with hybrid conversion and spike timing dependent backpropagation. arXiv preprint arXiv:2005.01807. https://doi.org/10.48550/arXiv.2005.01807

🔵	Rueckauer, B., Lungu, I. A., Hu, Y., Pfeiffer, M., & Liu, S. C. (2017). Conversion of continuous-valued deep networks to efficient event-driven networks for image classification. Frontiers in neuroscience, 11, 682. https://doi.org/10.3389/fnins.2017.00682

🔵	Lee, C., Sarwar, S. S., Panda, P., Srinivasan, G., & Roy, K. (2020). Enabling spike-based backpropagation for training deep neural network architectures. Frontiers in neuroscience, 14, 497482. https://doi.org/10.3389/fnins.2020.00119

🔵	Wu, Y., Deng, L., Li, G., Zhu, J., Xie, Y., & Shi, L. (2019, July). Direct training for spiking neural networks: Faster, larger, better. In Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, pp. 1311-1318). https://doi.org/10.1609/aaai.v33i01.33011311

🔵	Rathi, N., & Roy, K. (2020). Diet-snn: Direct input encoding with leakage and threshold optimization in deep spiking neural networks. arXiv preprint arXiv:2008.03658. https://doi.org/10.48550/arXiv.2008.03658

🔵	Han, B., Srinivasan, G., & Roy, K. (2020). Rmp-snn: Residual membrane potential neuron for enabling deeper high-accuracy and low-latency spiking neural network. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 13558-13567). https://doi.org/10.48550/arXiv.2003.01811

🔵	Lu, S., & Sengupta, A. (2020). Exploring the connection between binary and spiking neural networks. Frontiers in neuroscience, 14, 535. https://doi.org/10.3389/fnins.2020.00535

🔵	Lee, J. H., Delbruck, T., & Pfeiffer, M. (2016). Training deep spiking neural networks using backpropagation. Frontiers in neuroscience, 10, 508. https://doi.org/10.3389/fnins.2016.00508

🔵	Wu, Y., Deng, L., Li, G., Zhu, J., & Shi, L. (2018). Spatio-temporal backpropagation for training high-performance spiking neural networks. Frontiers in neuroscience, 12, 331. https://doi.org/10.3389/fnins.2018.00331

🔵	Shrestha, S. B., & Orchard, G. (2018). Slayer: Spike layer error reassignment in time. Advances in neural information processing systems, 31. https://doi.org/10.48550/arXiv.1810.08646

🔵	Jin, Y., Zhang, W., & Li, P. (2018). Hybrid macro/micro level backpropagation for training deep spiking neural networks. Advances in neural information processing systems, 31. https://doi.org/10.48550/arXiv.1805.07866

🔵	Kugele, A., Pfeil, T., Pfeiffer, M., & Chicca, E. (2020). Efficient processing of spatio-temporal data streams with spiking neural networks. Frontiers in neuroscience, 14, 512192. https://doi.org/10.3389/fnins.2020.00439

🔵	Wu, H., Zhang, Y., Weng, W., Zhang, Y., Xiong, Z., Zha, Z. J., ... & Wu, F. (2021, May). Training spiking neural networks with accumulated spiking flow. In Proceedings of the AAAI conference on artificial intelligence (Vol. 35, No. 12, pp. 10320-10328). https://doi.org/10.1609/aaai.v35i12.17236

🔵	Aayush Ankit, Abhronil Sengupta, Priyadarshini Panda, and Kaushik Roy. 2017. RESPARC: A reconfigurable and energy-efficient architecture with memristive crossbars for deep spiking neural networks. In 54th Annual Design Automation Conference. ACM, 27. https://doi.org/10.48550/arXiv.1702.06064

🔵	Alireza Bagheri, Osvaldo Simeone, and Bipin Rajendran. 2018. Adversarial training for probabilistic spiking neural networks. In IEEE 19th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). IEEE, 1–5. https://doi.org/10.48550/arXiv.1802.08567

🔵	Gupta, A., & Long, L. N. (2007, August). Character recognition using spiking neural networks. In 2007 International Joint Conference on Neural Networks (pp. 53-58). IEEE. https://doi.org/10.1109/IJCNN.2007.4370930

🔵	Liang, L., Hu, X., Deng, L., Wu, Y., Li, G., Ding, Y., ... & Xie, Y. (2021). Exploring adversarial attack in spiking neural networks with spike-compatible gradient. IEEE transactions on neural networks and learning systems, 34(5), 2569-2583. https://doi.org/10.48550/arXiv.2001.01587

🔵	Neftci, E. O., Mostafa, H., & Zenke, F. (2019). Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks. IEEE Signal Processing Magazine, 36(6), 51-63. https://doi.org/10.1109/MSP.2019.2931595

🔵	Wang, X., Lin, X., & Dang, X. (2020). Supervised learning in spiking neural networks: A review of algorithms and evaluations. Neural Networks, 125, 258-280. https://doi.org/10.1016/j.neunet.2020.02.011
